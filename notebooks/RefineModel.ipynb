{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"seaborn-white\")\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.nn import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_processing import upsample, downsample\n",
    "from data import prepare_data, test_images_path, load_images_as_arrays, TGSSaltDataset\n",
    "from visualisation import (\n",
    "    plot_coverage_and_coverage_class,\n",
    "    scatter_coverage_and_coverage_class,\n",
    "    plot_depth_distributions,\n",
    "    plot_predictions,\n",
    "    plot_images,\n",
    ")\n",
    "from model import model_path, save_checkpoint, update_state\n",
    "from metrics import iou_metric_batch, my_iou_metric\n",
    "from toolz import compose\n",
    "from data import rle_encode\n",
    "import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from torch.utils import data\n",
    "\n",
    "from resnetlike import UNetResNet\n",
    "from training import train, test\n",
    "from collections import defaultdict\n",
    "import logging\n",
    "import random\n",
    "from utils import create_optimizer, tboard_log_path\n",
    "import uuid\n",
    "import itertools as it\n",
    "from operator import itemgetter\n",
    "import shutil\n",
    "from losses import lovasz_hinge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size_target = 101\n",
    "batch_size = 128\n",
    "learning_rate = 0.1\n",
    "epochs = 70\n",
    "num_workers = 0\n",
    "seed = 42\n",
    "num_cycles = (\n",
    "    6\n",
    ")  # Using Cosine Annealing with warm restarts, the number of times to oscillate\n",
    "notebook_id = f\"{now:%d%b%Y}_{uuid.uuid4()}\"\n",
    "base_channels = 32\n",
    "optim_config = {\n",
    "    \"optimizer\": \"sgd\",\n",
    "    \"base_lr\": 0.01,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"nesterov\": True,\n",
    "    \"epochs\": epochs,\n",
    "    \"scheduler\": \"cosine\",\n",
    "    \"lr_min\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(f\"Started {now}\")\n",
    "tboard_log = os.path.join(tboard_log_path(), f\"log_{notebook_id}\")\n",
    "logger.info(f\"Writing TensorBoard logs to {tboard_log}\")\n",
    "summary_writer = None  # SummaryWriter(log_dir=tboard_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNetResNet(1, base_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_params = sum([param.view(-1).size()[0] for param in model.parameters()])\n",
    "logger.info(\"n_params: {}\".format(n_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "model = nn.DataParallel(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = prepare_data()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_train, ids_valid, x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test = train_test_split(\n",
    "    train_df.index.values,\n",
    "    np.array(train_df.images.tolist()).reshape(\n",
    "        -1, 1, img_size_target, img_size_target\n",
    "    ),\n",
    "    np.array(train_df.masks.tolist()).reshape(\n",
    "        -1, 1, img_size_target, img_size_target\n",
    "    ),\n",
    "    train_df.coverage.values,\n",
    "    train_df.z.values,\n",
    "    test_size=0.2,\n",
    "    stratify=train_df.coverage_class,\n",
    "    random_state=seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment data with flipped verisons\n",
    "x_train = np.append(x_train, [np.fliplr(x) for x in x_train], axis=0)\n",
    "y_train = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TGSSaltDataset(x_train, y_data=y_train)\n",
    "dataset_val = TGSSaltDataset(x_valid, y_data=y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_data_loader = data.DataLoader(\n",
    "    dataset_val,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_config[\"steps_per_epoch\"] = len(train_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lovasz_history = defaultdict(list)\n",
    "loss_fn = lovasz_hinge\n",
    "\n",
    "global_counter = it.count()\n",
    "cumulative_epochs_counter = it.count()\n",
    "cycle_best_val_iou = {}\n",
    "for cycle in range(num_cycles):  # Cosine annealing with warm restarts\n",
    "    optimizer, scheduler = create_optimizer(model.parameters(), optim_config)\n",
    "    for epoch in range(epochs):\n",
    "        cum_epoch = next(cumulative_epochs_counter)\n",
    "        train_metrics = train(\n",
    "            cum_epoch,\n",
    "            model,\n",
    "            optimizer,\n",
    "            scheduler,\n",
    "            loss_fn,\n",
    "            train_data_loader,\n",
    "            config,\n",
    "            summary_writer=summary_writer,\n",
    "            global_counter=global_counter,\n",
    "            metrics_funcs=metrics,\n",
    "        )\n",
    "\n",
    "        val_metrics = test(\n",
    "            cum_epoch,\n",
    "            model,\n",
    "            loss_fn,\n",
    "            val_data_loader,\n",
    "            summary_writer=summary_writer,\n",
    "            metrics_funcs=metrics,\n",
    "        )\n",
    "\n",
    "        state = update_state(\n",
    "            state, cum_epoch, \"val_iou\", np.mean(val_metrics[\"iou\"]), model, optimizer\n",
    "        )\n",
    "\n",
    "        save_checkpoint(\n",
    "            state, best_model_filename=f\"model_lovasz_{cycle}_best_state.pth\"\n",
    "        )\n",
    "\n",
    "        lovasz_history[\"epoch\"].append(cum_epoch)\n",
    "        lovasz_history[\"train_loss\"].append(np.mean(train_metrics[\"loss\"]))\n",
    "        lovasz_history[\"val_loss\"].append(np.mean(val_metrics[\"loss\"]))\n",
    "        lovasz_history[\"train_iou\"].append(np.mean(train_metrics[\"iou\"]))\n",
    "        lovasz_history[\"val_iou\"].append(np.mean(val_metrics[\"iou\"]))\n",
    "    cycle_best_val_iou[cycle] = state[\"best_val_iou\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_val_iou = sorted(cycle_best_val_iou.items(), key=itemgetter(1), reverse=True)\n",
    "best_cycle, best_iou = sorted_by_val_iou[0]\n",
    "logger.info(f\"Best model cycle {best_cycle}: Validation IoU {best_iou}\")\n",
    "logger.info(\"Saving to model_lovasz_state.pth\")\n",
    "shutil.copy(\n",
    "    os.path.join(model_path(), f\"model_lovasz_{best_cycle}_best_state.pth\"),\n",
    "    os.path.join(model_path(), f\"model_lovasz__best_state.pth\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax_loss, ax_iou) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "ax_loss.plot(lovasz_history[\"epoch\"], lovasz_history[\"train_loss\"], label=\"Train loss\")\n",
    "ax_loss.plot(\n",
    "    lovasz_history[\"epoch\"], lovasz_history[\"val_loss\"], label=\"Validation loss\"\n",
    ")\n",
    "ax_loss.legend()\n",
    "ax_iou.plot(lovasz_history[\"epoch\"], lovasz_history[\"train_iou\"], label=\"Train IoU\")\n",
    "ax_iou.plot(lovasz_history[\"epoch\"], lovasz_history[\"val_iou\"], label=\"Validation IoU\")\n",
    "ax_iou.legend()"
   ]
  }
 ],
 "metadata": {
  "jupytext_formats": "ipynb,py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
